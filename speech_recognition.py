# -*- coding: utf-8 -*-
"""speech_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zj2dfq54TyDo1e-s0xEzJme5FVzTCSPK
"""

import librosa # module for dealing with sound 
import os # Dealing with system files and merging and what is inside them 
import numpy as np # Dealing with maths 
import IPython.display as ipd # Running audio files 
from sklearn.preprocessing import LabelEncoder # preparing audio files for processing / dealing with data 
from keras.utils import np_utils # dealing with neural network 
from sklearn.model_selection import train_test_split
from keras.models import load_model
from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D
#Dense = fully connected network , the hidden layer named Dense Like mesh tobology(circles in dense we defined 
#how many circles)
# flatten : befor enter to dense befor training , sounds represent in array flatten make this sounds in
# in one beam , many lines and one column
# conv1d one demenision related to the sound extract featchers 
# input to preper befor input to neural network
from keras.models import Model# in module we put the network that we made , and containe compiler that give me 
# the rate of accuracy , told me the predect is true like 87% the output is correct , accuracy of output predect
#loss function , optimizer = adam (calsiification )
#30 folder of sound 
from keras.callbacks import EarlyStopping, ModelCheckpoint
# told the model  during his training if acuurecy between to step there is no differnet in % stop training 
#no adder to acuuracy 
# modelCheckpoint make save
from keras import backend as K
#import sounddevice as sd
#import soundfile as sf

!sudo apt-get install libportaudio2

# in this way ...during we are using collab we are saving (training file for neural network)  on drive 
#to continue training from the last point we reachedin training 
from google.colab import drive

drive.mount('/content/drive',force_remount=True)

#import training files from the "tensorflow"
!wget "http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz"

# making file and named it "data" to save dataset in it then extract dataset in data file 

cd "/content/data"

#extract data in  "/content/data"
!tar -xvf '/content/data/speech_commands_v0.01.tar.gz'

#delated unused file 
!rm -r "/content/data/LICENSE"
!rm -r "/content/data/README.md"
!rm -r "/content/data/speech_commands_v0.01.tar.gz"
!rm -r "/content/data/testing_list.txt"
!rm -r "/content/data/validation_list.txt"
!rm -r "/content/data/_background_noise_"

train_audio_path = '/content/data'
# readind all files in the path below 
labels=os.listdir(train_audio_path)

all_wave = []
#represent the sound for training and had to features (sample sound like array )(sample rate represent the hz)
all_label = []
# repesent the correct output ( for comparing)
for label in labels:
    print(label)
    # give what the file have in inside (all files such as (bird has sounds >> enter to it and show me this sound ))
    # contain the [path.wave]
    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]
    #after give me all files.wav
    #librosa reading soundfile & return samples & sample rate 
    # we modifi sr = 8000 because that is suitable for sound recogntion 
    for wav in waves:
        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)
        samples = librosa.resample(samples, sample_rate, 8000)
        if(len(samples)== 8000) : 
            all_wave.append(samples)
            all_label.append(label)
# in training we give him input and output

# from sk learn make data (samples) ready  for inter to neural  network 
le = LabelEncoder()
y=le.fit_transform(all_label)#numberd samples
classes= list(le.classes_)#below when making predict ..give me int and this int refer to name of list below

print(classes)

y=np_utils.to_categorical(y, num_classes=len(labels))
## make table the colomn is name of sound folder and enter is sound that you give him to check
#then it will put 1 in what opposit
#array 2*2 to enter it to the flatten (one col and many lines) because n n dont understand string

y

all_wave = np.array(all_wave).reshape(-1,8000,1)
#because list cant inter to neural  network we make all_wave an array  and reshape it

all_wave

x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)
#sk learn after train go to validation to evalution

model=load_model('/content/drive/MyDrive/best_model.hdf5')



K.clear_session()

inputs = Input(shape=(8000,1))

#First Conv1D layer
conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)
conv = MaxPooling1D(3)(conv)
conv = Dropout(0.3)(conv)

#Second Conv1D layer
conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)
conv = MaxPooling1D(3)(conv)
conv = Dropout(0.3)(conv)

#Third Conv1D layer
conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)
conv = MaxPooling1D(3)(conv)
conv = Dropout(0.3)(conv)

#Fourth Conv1D layer
conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)
conv = MaxPooling1D(3)(conv)
conv = Dropout(0.3)(conv)

#Flatten layer
conv = Flatten()(conv)

#Dense Layer 1
conv = Dense(256, activation='relu')(conv)
conv = Dropout(0.3)(conv)

#Dense Layer 2
conv = Dense(128, activation='relu')(conv)
conv = Dropout(0.3)(conv)

outputs = Dense(len(labels), activation='softmax')(conv)

model = Model(inputs, outputs)
model.summary()

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

from keras.callbacks import EarlyStopping, ModelCheckpoint
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) 
mc = ModelCheckpoint('/content/best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')



history=model.fit(x_tr, y_tr ,epochs=100, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))

model.save(filepath="/content/drive/MyDrive/best_model.hdf5")

def predict(audio):
    prob=model.predict(audio.reshape(1,8000,1))
    index=np.argmax(prob[0])
    return classes[index]

# import random  "/content/sample_data/13.wav"
# index=random.randint(0,len(x_val)-1)
# samples=x_val[index].ravel()
samples, sample_rate = librosa.load("/content/drive/MyDrive/27 zero.wav", sr = 16000)
samples = librosa.resample(samples, sample_rate, 8000)
# print("Audio:",classes[np.argmax(y_val[index])])
# ipd.Audio(samples, rate=8000)
print("Text:",predict(samples))











samplerate = 16000  
duration = 1 # seconds
filename = 'yes.wav'
print("start")
mydata = sd.rec(int(samplerate * duration),
                samplerate=samplerate,
    channels=1, blocking=True)
print("end")
sd.wait()
sf.write(filename, mydata, samplerate)

os.listdir('../input/voice-commands/prateek_voice_v2')
filepath='../input/voice-commands/prateek_voice_v2'

#reading the voice commands
samples, sample_rate = librosa.load(filepath + '/' + 'stop.wav', sr = 16000)
samples = librosa.resample(samples, sample_rate, 8000)
ipd.Audio(samples,rate=8000)  

predict(samples)



